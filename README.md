# Apex Discovery Engine ğŸš€

A high-performance, autonomous web scraping agent designed to discover, extract, and organize lead data (PGs, Hostels, Businesses) from the web.

## ğŸŒŸ Key Features

- **Multi-Engine Discovery**: Intelligently switches between Brave, Bing, DuckDuckGo, and Google Maps to find targets.
- **Deep Crawling**: Automatically navigates to "Contact Us" pages and detail views to uncover hidden numbers.
- **Google Maps dedicated Scraper**: Bypasses website blocks by extracting direct phone numbers from Google Maps side panels.
- **Resumable State**: Remembers where it left off (pagination handling).
- **Smart Deduplication**: Uses advanced heuristics to remove duplicate entries while preserving unique leads.
- **Excel Export**: Delivers clean, structured data ready for use.

## ğŸ“‚ Project Structure

The project follows a modular, professional architecture:

```
/
â”œâ”€â”€ main.py                 # Entry point (Unified CLI & Interactive Mode)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cli.py              # CLI Command Definitions
â”‚   â”œâ”€â”€ core/               # Core Utilities & Configuration
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ scrapers/           # scraping Logic Modules
â”‚   â”‚   â”œâ”€â”€ search.py       # Search Engine Connectors (Brave, Bing, etc.)
â”‚   â”‚   â”œâ”€â”€ listing.py      # Website Extraction Logic (HTML Parsing)
â”‚   â”‚   â””â”€â”€ maps.py         # Google Maps Side-Panel Scraper
â”‚   â””â”€â”€ exporters/          # Data Export Modules
â”‚       â””â”€â”€ excel.py        # Excel Export Logic
â”œâ”€â”€ scripts/                # Helper & Debug Scripts
â”‚   â”œâ”€â”€ analyze_yield.py
â”‚   â””â”€â”€ ...
â””â”€â”€ data/                   # Data Storage (JSON/Excel)
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Playwright

### Installation

```bash
pip install -r requirements.txt
playwright install chromium
```

### Usage

**1. Interactive Mode (Recommended)**

```bash
python main.py
```

Follow the on-screen prompts to discover and extract data.

**2. CLI Commands**

- **Discover URLs**:

  ```bash
  python main.py discover --query "PG in Ahmedabad" --limit 50
  ```

- **Maps Scraper (High Yield)**:

  ```bash
  python main.py maps --query "PG in Ahmedabad" --limit 100
  ```

- **Extract Data from URLs**:

  ```bash
  python main.py extract
  ```

- **Export to Excel**:
  ```bash
  python main.py export
  ```

## ğŸ›  Advanced Configuration

Configuration settings (User Agents, Timeouts) can be found in `src/core/config.py`.

## ğŸ“ License

Proprietary Software.
